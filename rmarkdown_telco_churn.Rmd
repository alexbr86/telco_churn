---
title: "Churn Prediction"
author: "Author: 135430"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introducción
En este trabajo del modulo 5, se va a tratar el caso de Churn Prediction para el dataset de una compañia de telecomunicaciones. Se va a tratar de por un lado entender porque los clientes abandonan la compañia y por otro como detectar esa fuga en la medida de lo posible mediante analisis de los datos y aplicación de algoritmos supervisados.

## Repositorio
Todo el código como el dataset se encuentran el el siguiente repositorio de git junto con este mismo notebook en .rmd y html: https://github.com/alexbr86/telco_churn . 


## Inicialización

#### Funciones auxiliares para cargar paquetes y lista de paquetes

```{r}
prepare_packages <- function(packages){
  # Chequeamos que paquetes no estan instalados:
  non_intalled <- packages[!(packages %in% installed.packages()[, "Package"])]
  # En caso de existir alguno aún no instalado, lo instalamos:
  if (length(non_intalled)) 
    install.packages(non_intalled, dependencies = TRUE)
  # Cargamos toda la lista de paquetes:
  sapply(packages, require, character.only = TRUE)
}
packages <- c("tidyverse",
              "MASS",
              "car",
              "binr",
              "e1071",
              "caret",
              "cowplot",
              "caTools",
              "pROC",
              "ggcorrplot",
              "data.table",
              "Information",
              "rpart",
              "rpart.plot",
              "xgboost",
              "ROCR",
              "pROC",
              "GGally",
              "fastDummies"
)
prepare_packages(packages)
```


#### Cargar el dataset

```{r}
dataset <- read.csv("dataset/WA_Fn-UseC_-Telco-Customer-Churn.csv")
```


Se va a analizar el tipo de información que contiene el dataset

```{r}
glimpse(dataset)
```

#### Limpieza del dataset

Se va a cambiar los valores de la variable Senior Citizens valores categoricos de 'Yes', 'No'. Homogeneizando con el resto de variables categoricas.

```{r}
dataset$SeniorCitizen <- as.factor(ifelse(dataset$SeniorCitizen==1, 'Yes', 'No'))
```


A continuación se va a ver un resumen del dataset para poder entenderlo mejor y detectar información necesaria a primera vista.

```{r}
summary(dataset)
```


Tras ver el resumen, puede observarse que la variable TotalCharges tiene 11 NAs que habría que limipiar.Antes de ver que solución se le imputa al problema, es conveniente analizar el porqué son NAs, si es un fallo o hay algún motivo en los datos.

```{r}
dataset[is.na(dataset$TotalCharges),]
```


Tras analizar los 11 casos de NAs se ha observado que esto es debido a que son clientes recientes y no llevan aún ni un cargo acumulado, ya que como se ve en la columna Tenure llevan 0 meses en la compañia. Por lo que la mejor solución a este problema sería imputarles a todos un valor de 0. Primero se va a comprobar si hay más clientes que lleven 0 meses en la compañia y si tengan valor en TotalCharges

```{r}
dataset[dataset$tenure==0,]
```

Se comprueba que todos aquellos que llevan 0 meses son solo aquellos que tienen valores NA en TotalCharges. Por lo que se les va a asignar o como valor de pago acumulado en total.

```{r}
#Asignar valor 0 a todos aquellos que sean NA en TotalCharges
dataset[dataset$tenure==0, "TotalCharges"]=0
var_class <- sapply(dataset, class)
var_class_numeric <- names(dataset[var_class=="numeric"])
var_class_inter <- names(dataset[var_class=="integer"])
var_num_total <- c(var_class_numeric, var_class_inter)
var_numeric <- dataset[var_num_total]
```


## AutoML
Utilizando la libreria de H2O se va a probar como se comporta el dataset en limpio con un modelo y asi poder intuir de que modo proceder con el mismo.

Se va a dividir el dataset en train, validation y test.

```{r}
set.seed(46)
selected <- sample(1:nrow(dataset), 0.2*nrow(dataset))
train <- dataset[-selected,]
test <- dataset[selected,]
#Model
# Set names for h2o
target <- "Churn"
x <- setdiff(names(train), target)
```

Se va a lanzar todos los modelos supervisados excepto los referentes a Deep Learning y GLM.

```{r}
library(h2o)
h2o.init()
write.csv(train, file = "train.csv")
train2 = h2o.importFile("./train.csv")
write.csv(test, file = "test.csv")
test2 = h2o.importFile("./test.csv")
aml <- h2o.automl(x = x,
                 y = target,
                 validation_frame = test2,
                 training_frame = train2,
                 max_runtime_secs = 60,
                 exclude_algos = c("DeepLearning", "GLM", "DRF", "StackedEnsemble"))
```

Extraer los mejores modelos del train.
```{r}
automl_leader <- aml@leader
automl_leader_list <- aml@leaderboard
automl_leader_list
```

Ver la matriz de confusión

```{r}
h2o.confusionMatrix(automl_leader)
```


Variables más determinantes

```{r}
h2o.varimp_plot(automl_leader)
```


Las variables más determinantes teniendo en cuenta el mejor algoritmo seleccionado por AutoML son:
Contract: como variable más determinantes sería la duración del contrato.
TechSupport: la segunda más determinante si el cliente tiene soporte técnico.
Tenure: Es la tercera más determinante, cuanto tiempo lleva siendo cliente de la compañia.

## EDA

Ahora se va a analizar el dataset y sus variables. Con ello tratar de describir el dataset y obtener la mayor cantidad de información relevante para luego poder montar el modelo de predicción de abandono.

#### Variable target Churn
Primero se va a ver que porcentaje del dataset da positivo en abandono:
```{r}
options(repr.plot.width = 6, repr.plot.height = 4)
dataset %>% 
group_by(Churn) %>% 
summarise(Count = n())%>% 
mutate(percent = prop.table(Count)*100)%>%
ggplot(aes(reorder(Churn, -percent), percent), fill = Churn)+
geom_col(fill = c("#FF0800", "#170CEA"))+
geom_text(aes(label = sprintf("%.2f%%", percent)), hjust = 0.01,vjust = -0.5, size =3)+ 
theme_bw()+  
xlab("Churn") + 
ylab("Percent")+
ggtitle("Churn Percent")
```

Se puede observar que del dataset algo más de un 25% da positivo en abandono. Es una muestra bastante bien balanceada para lo que suele ser este tipo de casos, por lo que inicialmente podria ser viable descartar hacer down o up sampling.

#### Variables categoricas

Ahora vamos a ver como se distribuye la variable de Churn en el resto de variables categoricas:

```{r}
options(repr.plot.width = 12, repr.plot.height = 100)
plot_grid(ggplot(dataset, aes(x=gender,fill=Churn)) + geom_bar() + scale_fill_manual(values=c("#FF0800", "#170CEA")), 
          ggplot(dataset, aes(x=SeniorCitizen,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=Partner,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=Dependents,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=PhoneService,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=MultipleLines,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA"))
            + theme_bw()+
          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          align = 'v', ncol=2)
```

Como puede observarse en la mayoria de estas primeras variables se observa un equilibrio entre sus valores con respecto a la variable objetivo Churn. Aunque hay algunas que ya nos dan algun indicador de tendencia como:

+ SeniorCitizen, indica que si el cliente es senior o no, y en la gráfica se ve que los clientes senior tienen mayor tendencia a abandonar la compañia.
+ Partner, si el cliente tiene un partner o no, y hay una tendencia mayor al abandono entre los que no lo tienen.
+ Dependents, si el cliente dependientes, y se observa una tendencia mayor al abandono en los clientes que no tienen dependientes.


```{r}
options(repr.plot.width = 12, repr.plot.height = 100)
plot_grid(ggplot(dataset, aes(x=InternetService,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=OnlineSecurity,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=OnlineBackup,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=DeviceProtection,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=TechSupport,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA"))
            + theme_bw()+
          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          align = 'v', ncol=2)
```

+ InternetService, el tipo de servicio de internet si lo tiene, hay una tendencia clara al abandono entre los clientes que tienen fibra óptica.
+ OnlineSecurity, si el cliente tiene seguridad online, hay una tendencia clara al abandono entre los clientes que no tienen seguridad online.
+ OnlineBackup, si el cliente tiene backup online, se ve una tendencia al abandono aquellos que no tienen el servicio.
+DeviceProtection, si el cliente tiene protección para el dispositivo, hay una ligera tendendica al abandono en aquellos que no tienen este servicio.
+ TechSupport, si el cliente tiene soporte técnico, hay una tendencia clara al abandono entre los clientes que no tienen el servicio técnico.


```{r}
options(repr.plot.width = 12, repr.plot.height = 100)
plot_grid(ggplot(dataset, aes(x=StreamingTV,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=Contract,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=PaperlessBilling,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=PaymentMethod,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA"))
            
            + theme_bw()+
          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          align = 'v', ncol=2)
```

En estas últimas variables hay una tendencia en los valores de cada variable según la variable objetivo Churn:

+ StreamingTV, si el cliente servicio de TV Streamng, hay una ligera tendencia al abandono entre los clientes que tienen el servicio de TV Streaming y entiendiendo que se les puede sumar aquellos que no tienen servicio de internet ya que no disponen del servicio.
+ Contract, el tipo de contrato que tienen los clientes, hay una tendencia muy clara entre los clientes que tienen un contrato de mes a mes.
+ PaperlessBilling, si el cliente tiene factura digital, y hay una tendencia clara al abandono en los clientes que si tienen factura digital.
+ PaymentMethod, el metodo de pago del cliente, hay una tendencia clara al abandono entre los clientes que tienen de metodo de pago con cheque electronico.

#### Variables continuas

Se va a tratar de analizar del mismo modo, el comportamiento de las variables continuas con respecto la variable de abandono, Churn:

Disposicion de la variable TotalCharges contra la variable objetivo:

```{r}
dataset %>% ggplot(aes(x=TotalCharges,fill=Churn))+ geom_density(alpha=0.8)+scale_fill_manual(values=c("#FF0800", "#170CEA"))+labs(title='Total Charges desnisty split churn vs non churn' )
```

Como se puede comprobar con este gráfico podemos observar que los usuarios cuanto menos tienen acumulado de pago más tienden al abandono.


```{r}
options(repr.plot.width = 6, repr.plot.height = 2)
ggplot(dataset, aes(y=TotalCharges, x=" ", fill=Churn))+ 
  scale_fill_manual(values=c("#FF0800", "#170CEA"))+
  geom_boxplot()+
  theme_bw()
```

Se puede confirmar lo visto en el gráfico anterior donde se ve una diferencia clara entre los segundos quartiles o medias de los que si y no abandonan. Viendo que hay una tendencia al abandono en aquellos que llevan menos cargos acumulados. Aunque puede verse algunos outliers, no tiene mucho aspecto de serlo, más bien pueden ser usuarios que lleven mucho tiempo ya en la compañia con cargos acumulados y que tiendan a hacer un cambio.


Disposicion de la variable MonthlyCharges contra la variable objetivo:

```{r}
dataset %>% ggplot(aes(x=MonthlyCharges,fill=Churn))+ geom_density(alpha=0.8)+scale_fill_manual(values=c("#FF0800", "#170CEA"))+labs(title='Monthly Charges desnisty split churn vs non churn' )
```

En cambio en el siguiente gráfico se puede observar que los que menos pagan mensualmente tienen a permanecer en la compañia mientras que los que más pagan tienen al abandono.

Boxplot de la variable MonthlyCharges sobre la objetivo Churn.

```{r}
options(repr.plot.width = 6, repr.plot.height = 2)
ggplot(dataset, aes(y=MonthlyCharges, x=" ", fill=Churn))+ 
  scale_fill_manual(values=c("#FF0800", "#170CEA"))+
  geom_boxplot()+
  theme_bw()
```

Se ve una distrubución con valores altos más compactos en los que tienen tendencia al abandono contra los que no tienen, que es una distibución donde el primer quartil tiene un valor mucho más bajo y el segundo esta más parejo. Esto puede entenderse como que los que tienen tendencia al abandono tienen unos cargos mensuales altos frente a los que no lo tienen que esta algo más distribuido aunque con unos valores más bajos.


Distribución de la variable tenure:

```{r}
dataset %>% ggplot(aes(x=tenure,fill=Churn))+ geom_density(alpha=0.8)+scale_fill_manual(values=c("#FF0800", "#170CEA"))+labs(title='Tenure desnisty split churn vs non churn' )

```

Con el gráfico que puede observarse arriba se ve la relación entre el tiempo que lleva el usuario en la compañia y el abandono. Donde hay una tendencia clara a cuanto menos tiempo lleven en la compañia más abandono hay. Mientras que a medida que van avanzando en el tiempo de estancia en la compañia la tendencia del abandono tiende a menos.

Boxplot de la variable Tenure sobre la objetivo Churn.

```{r}
options(repr.plot.width = 6, repr.plot.height = 2)
ggplot(dataset, aes(y=tenure, x=" ", fill=Churn))+ 
  scale_fill_manual(values=c("#FF0800", "#170CEA"))+
  geom_boxplot()+
  theme_bw()
```

Se ve una diferencia bastante notable entre los usuarios que tienen más tendencia al abandono con los que no. Puede deducirse que los usuarios con mayor tendencia al abandono tienen unos valores de tenure bastante más bajos ya que el segundo quartil de los de no abandono esta en 40 meses frente a los que si con 10 meses. Esto confirma lo visto en la anterior gráfica donde se intuia que los usuarios con mayor tendencia al abandono son los que menos tiempo llevan en la compañia.


Distribución de las variables en scatterplot onde se va a observar alguna dependencia o correlación entre ellas y detección de outliers.

```{r}
ggpairs(var_numeric, title = "Distribución de las variables continuas")
```


Tras observar posibles correlaciones entre las variables continuas, se ve necesario ver la matriz de correlaciones para poder definir las posibles dependencias que se empiezan a observar en el gráfico de distribución de las variables continuas.

```{r}
corr <- cor(var_numeric,  method = "pearson", use = "complete.obs")
ggcorrplot(corr, hc.order = TRUE, type = "lower",
   lab = TRUE)
```

Tras analizar la matriz de correlaciones, puede observarse una alta dependencia positiva de la variable TotalCharges con Tenure y una algo más moderada con la otra variable MonthlyCharges.


#### Information value:


```{r}
dataset_inf <- dataset
dataset_inf$Churn <- as.numeric(ifelse(dataset_inf$Churn=='Yes', 1, 0))
iv_ds <- create_infotables(data=dataset_inf,
                           y="Churn")
iv_summary <- iv_ds$Summary
iv_summary <- iv_summary[order(iv_summary$IV), ]
iv_summary$Variable <- factor(iv_summary$Variable, levels=iv_summary$Variable)
ggplot(iv_summary, aes(x=Variable, y=IV, fill = IV))+
  coord_flip() +
  scale_fill_gradient(low = "grey", high = "green") +
  geom_bar(stat = "identity")
```


Ahora a verse el indicador de WOE para las tres principales variables vistas en los datos del information value.
WOE segun la  Contract:

```{r}
ggplot(iv_ds$Tables$Contract, aes(x=Contract, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```

Se empieza a confirmar lo visto anteriormente con una disposición al abandono aquellos que tienen un tipo de contrato de mes a mes frente al resto.

WOE según tenure:

```{r}
ggplot(iv_ds$Tables$tenure, aes(x=tenure, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```

Aquí también se confirma lo visto anteriormente que hay una tendencia importante al abandono en aquellos que llevan menos menos tiempo en la compañia.


```{r}
ggplot(iv_ds$Tables$OnlineSecurity, aes(x=OnlineSecurity, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```

En si los usuarios tienen servicio de seguridad online, se confirma una tendencia al abandono entre aquellos que no disponen de ese servicio.

#### Conclusiones EDA

Tras analizar todas y cada una de las variables y sus ditribuciones ya se ve un perfil claro el cual tiene la tendencia al abandono donde toman parte con más fuerza unas variables frente a otras. 

Es un cliente que como bien se ve con las variables tenure, contract o totalcharges, lleva poco tiempo en la compañia lo cual tiene un cargo acumulado menor, tiene un contrato que se renueva mes a mes y lo que esto implica también un cargo mensual más alto. 

Además se ve que sus condiciones son bastante básicas ya que tiende a carecer de servicios adicionales como el de OnlineSecurity, StreamingTV, DeviceProtection, OnlineBackup, TechSupport.
Es un perfil de cliente que no suele tener Parners o Dependencies y que suele pagar con Electronic check.

Con todo esto puede resumirse en un perfil de cliente que busca un servicio de fibra óptica barato, sin ningún compromiso y tiende a ir de compañia en compañia haciendo pruebas de menos de año y medio sin muchas ataduras.


## Modelado de los algoritmos

#### Instalación de librerias de depencias y prevencion/solventar errores

```{r}
# Installation of the doSNOW parallel library with all dependencies
doInstall <- TRUE # Change to FALSE if you don't want packages installed.
toInstall <- c("doSNOW") 
if((doInstall) && (!is.element(toInstall, installed.packages()[,1])))
{
    cat("Please install required package. Select server:"); chooseCRANmirror();
    install.packages(toInstall, dependencies = c("Depends", "Imports")) 
}

# load doSnow and (parallel for CPU info) library
library(doSNOW)
library(parallel)

# For doSNOW one can increase up to 128 nodes
# Each node requires 44 Mbyte RAM under WINDOWS.

# detect cores with parallel() package
nCores <- detectCores(logical = FALSE)
cat(nCores, " cores detected.")

# detect threads with parallel()
nThreads<- detectCores(logical = TRUE)
cat(nThreads, " threads detected.")

# Create doSNOW compute cluster (try 64)
# One can increase up to 128 nodes
# Each node requires 44 Mbyte RAM under WINDOWS.
cluster = makeCluster(nThreads, type = "SOCK")
class(cluster);

# register the cluster
registerDoSNOW(cluster)

#get info
getDoParWorkers(); getDoParName();

# insert parallel computation here
        
# stop cluster and remove clients
stopCluster(cluster); print("Cluster stopped.")

# insert serial backend, otherwise error in repetetive tasks
registerDoSEQ()

# clean up a bit.
invisible(gc); remove(nCores); remove(nThreads); remove(cluster); 
```


#### Featuring engineering

Se ha visto que algunas variables categoricas dan la misma información en valores diferentes, como:  'No' y 'No Internet Service' o 'No Phone Service' y "NO". Por lo tanto se van a reducir para no tener variables con la misma información en dos variables, cuando se pasen a dummies.

```{r}
dataset_featured <- dataset
dataset_featured <- data.frame(lapply(dataset_featured, function(x) {
                  gsub("No internet service", "No", x)}))

dataset_featured <- data.frame(lapply(dataset_featured, function(x) {
                  gsub("No phone service", "No", x)}))
```

En cuanto a las variables continuas, primero se va a confirmar y estandarizar que todas son numéricas.

```{r}
num_columns <- c("tenure", "MonthlyCharges", "TotalCharges")
dataset_featured[num_columns] <- sapply(dataset_featured[num_columns], as.numeric)

```

A continuación se a escalar las variables continuas para poder tratar mejor con ellas en los modelos y que esten bajo el mismo rango a la hora de que el modelo pueda entender el peso de cada una.

```{r}
dataset_featured$tenure <- scale(dataset_featured$tenure, scale = T)
dataset_featured$MonthlyCharges <- scale(dataset_featured$MonthlyCharges, scale = T)
dataset_featured$TotalCharges <- scale(dataset_featured$TotalCharges, scale = T)
```


Pasar las variables categoricas a dummies para poder trabajar con ellas en los modelos.

```{r}
dataset_churn_factor <- dataset_featured
dataset_churn_factor$Churn <- as.factor(ifelse(dataset_churn_factor$Churn=='Yes', 1, 0)) 
data_model <- dataset_churn_factor[,!names(dataset_churn_factor) %in% c("customerID")]
var_categoric <- names(data_model[,!names(data_model) %in% c(var_num_total, "Churn")])
data_model_dummy <- dummy_cols(data_model, select_columns = var_categoric, remove_first_dummy = TRUE)
data_model_dummy_only <- data_model_dummy[,!names(data_model_dummy) %in% var_categoric]  
```

#### Dividir entre entrenamiento y test

```{r}
train <- createDataPartition(data_model_dummy_only$Churn, p = 0.8, list = F)
data_train <- data_model_dummy_only[train,]
data_test <- data_model_dummy_only[-train,]
dim(data_train)
dim(data_test)
```

#### GLM

Antes de empezar mencionar como se entiende que se debiera valorar o que métricas debieran primar a la hora de evaluar los modelos. Como lo que se trata de detectar el mayor numero de clientes que abandonen la compañia y que no se escape ninguno, hay que tener más en cuenta la sensibilidad (ya que como valor positivo se va a tratar el 1 de abandono, ya que se quiere optimizar para su detección) junto con el auc, aunque se buscará un equilibrio de todo.

Por otro lado, a la hora de entrenar cada modelo, se va a hacer con el metodo de cross validation, que consiste en dividir la muestra por n y cada división hara una vez de test. Para entrenar con diferentes muestras y luego sacar un promedio de todos los resultados. De esta manera se eficienta el entrenaimiento, ya que se entrena varias veces con diferentes modelos. Además se ha decido tras algunas pruebas de concepto, que el dataset si que puede tener algo de desbalanceo, por lo que se ha seleccionado la tecnica de Oversampling, SMOTE. Este metodo selecciona dos instancias similares utilizando vecinos más cercanos y bootstrapping, y genera muestras sintéticas a partir de instancias de las clases minoritarias.

Se va a entrenar el modelo de GLM

```{r}
set.seed(46)
# Definir train control para cross validation
train_control <- trainControl(method="cv", number=10, sampling="smote")
# Entrenar el modelo
model_glm_train <- train(Churn~., data=data_train, trControl=train_control, method="glm")
# Imprimir resultados
print(model_glm_train)
```

Una vez entrenado y viendo que el accuracy en entrenamiento es menor del resultado de H2O de AutoML, se va a comprobar su eficiencia predictora y a hacer la matriz de confusión.

```{r}
model_glm_predict <- predict(model_glm_train, data_test)
confusionMatrix(model_glm_predict, data_test$Churn, positive = "1")
```


Por lo tanto este algoritmo tiene un buen auc con una sensiblidad y especificidad buenas y equilibradas. Detecta bastante bien los verdaderos positivos en abandono y los falsos negativos.

#### GBM

Se va a entrenar el modelo seleccionado por H20.AutoML como mejor.

```{r}

set.seed(46)
# Definir train control para cross validation
train_control <- trainControl(method="cv", number=10, sampling = "smote")
# Entrenar el modelo
model_gbm_train <- train(Churn~., data=data_train, trControl=train_control, method="gbm", verbose = FALSE)
# Imprimir resultados
print(model_gbm_train)
```

En este se indica la mejor configuración del set de entrenamiento para el modelo de GBM. Esto lleva a un auc que sigue siendo menor al que ha salido con H2o. Ahora va a procederse a predecir con el test y ver la matriz de confusión que tal se comporta.

```{r}
model_gbm_predict <- predict(model_gbm_train,data_test)
confusionMatrix(model_gbm_predict,data_test$Churn, positive = "1")
```

Este modelo da un auc algo mas alto, aunque la sensibilidad es algo más baja ya que hay más falsos negativos que en el anterior modelo. Como se ha comentado, aunque la idea es optimizar todos los indicadores, prima el poder detectar todos los que realmente son positivos.

#### XGBoost

```{r}

set.seed(46)
# Definir train control para cross validation
train_control <- trainControl(method="cv", number=10, sampling = "smote")
# Entrenar el modelo
model_xgb_train <- train(Churn~., data=data_train, trControl=train_control, method="xgbTree", verbose = FALSE)
# Imprimir resultados
print(model_xgb_train)
```

Tras entrenar el modelo con XGBoost se encuentra una combinación de parametros donde como resultante el auc aún menor que el resultado de H20. Se va a proceder a predecir y ver la matriz de confusión para ver como se comporta el modelo.

```{r}
model_xgb_predict <- predict(model_xgb_train,data_test)
confusionMatrix(model_xgb_predict,data_test$Churn, positive = "1")
```

Este algoritmo finalmente tiene un auc similar al anterior aunque tiene una sensibilidad peor, ya que como puede observase en la matriz de confusión los falsos negativos son más altos aún que en los anteriores casos.


#### Random Forest

```{r}
set.seed(46)
# Definir train control para cross validation
train_control <- trainControl(method="cv", number=10, sampling = "smote")
# Entrenar el modelo
model_rf_train <- train(Churn~., data=data_train, trControl=train_control, method="rf", verbose = FALSE)
# Imprimir resultados
print(model_rf_train)
```

Tras el entrenamiento el algoritmo de Random Forest da un auc aún inferior al resultado obtenido en H2O. Se a a ver que tal se comporta prediciendo con la parte del test y viendo la matriz de confusión.

```{r}
model_rf_predict <- predict(model_rf_train,data_test)
confusionMatrix(model_rf_predict,data_test$Churn, positive = "1")
```

Este modelo tiene un auc de los más altos hasta ahora. No obstante aunque es el segundo algoritmo en verdaderos positivos (detectar la gente que va a abandonar), tiene una sensibilidad algo baja con respecto a algún otro modelo, lo que hace que este más alto los falsos negativos (gente que realmente abandona la compañia pero que el algoritmo predice que no van a abandonar).


#### GLMNET

```{r}
set.seed(46)
# Definir train control para cross validation
train_control <- trainControl(method="cv", number=10, sampling = "smote")
# Entrenar el modelo
model_glmnet_train <- train(Churn~., data=data_train, trControl=train_control, method="glmnet")
# Imprimir resultados
print(model_glmnet_train)
```

Tras ver que el modelo de GLMNET con el set de entrenamiento da que tampoco supera el modelo de H20 con las parametrizaciones optimizadas, se va a comprobar como se comporta prediciendo y en la matriz de confusión.

```{r}
model_glmnet_predict <- predict(model_glmnet_train,data_test)
confusionMatrix(model_glmnet_predict,data_test$Churn, positive = "1")
```

Este modelo tiene un auc algo por debajo de algunos pero con una sensibilidad mayor y una especificidad no tan alta como otros. Aún así no es el algoritmo con la sensibilidad, especificidad y auc más equilibradas pero no por mucho. Es el segundo algoritmo con mayor acierto en verdaderos positivos y que menos tiene en falsos negativos. 


#### Conclusiones del modelado

Después de varias pruebas de concepto:

+ probando con diferentes featuring egineering (categorizar tenure, escalar de modo continua, agregar valores de "NO" y "No internet service",...) y sin ellas, 
+ probando sin y con oversampling (down y SMOTE), 
+ usando el paquete caret que prueba con diferentes hiperparamtros en el entrenamiento para cada algoritmo y les asigna la mejor combinación de ellos, 
+ probar con varios algoritmos, confunciones de cross validation,

Tras todas estas pruebas, se ha mostrado la mejor solución o elección en cada caso. Una vez analizado cada algoritmo para las mejores soluciones o elecciones planteadas se ha observado que el algoritmo que mejor se adapta a la casuistica con los resultados y metricas ofrecidos es GLM. 

Con este algotimo se ha logrado un auc de 76% con una sensibilidad del 71% y una especificidad del 78%. Estos datos en general no son malos, es un buen comienzo de modelado. Aún así no supera el auc y la especificidad (84% y 90%) del de H2O que era un GBM. Pero como se mencionaba antes, la sensibilidad o ser capaz de acertar el mayor numero de abandonos sin errar en exceso en los falsos negativos es bastante importante. Ya que de cara a negocio es mucho mejor detectar realmente quienes se van y fallar alguno diciendo que se va y luego no; que detectar muy bien quienes se quedan y fallar algo más diciendo que no se van cuando luego sí. Y en ese caso este algoritmo de GLM es mejor que el de H2O (71% frente a 59%) que sus metricas son altas por acertar quienes no se van.

Por tanto puede entenderse que en ciertos aspectos de eficiencia, el algoritmo de GLM es mejor que el de H2O (GBM) y por consiguiente lo supera.

Las variables más importantes de este algoritmo han sido:

```{r}
plot(varImp(model_glm_train))
```

Como puede verse en el gráfico hay variables dummies por lo que habría que valorar tanto la variable en si como en los valores que se fija y en los ausentes. Como se puede ver la variable más importante es la de que tipo de contrato, el servicio de internert y el tiempo de estancia en la compañia. Variables que en el EDA ya se veian con una tendencia significativa. Lo que por lo tanto, viendo el gráfico se confirma las hipotesis que se lanzaban al inicio y las conclusiones plateadas tras el EDA.


## Conslusiones

En la problematica de abandono de clientes para una empresa de telecomunicaciones se ha ido tratando la problematica por partes. Por un lado se ha tratado de entender quienes y porque se van a través del EDA, analizando las variables y sus indicadores. Estos han generado un perfil claro, "Los veletas inconformistas".

Este perfil es un perfil como se ha mencionado antes, lleva poco tiempo en la compañia lo cual tiene un cargo acumulado menor, tiene un contrato que se renueva mes a mes y lo que esto implica también un cargo mensual más alto. Además es un perfil que busca satisfacer lo necesario con condiciones son bastante básicas y sin ataduras con otro cliente o dependencias, busca algo más impersonal pagando de modo electrónico. 

Por todo ello se ve que son gente que va de compañia en compañia buscando un buen precio con una franja de tiempo reducida, no desea ataduras ya que pide un servicio básico como por ejemplo del de fibra óptica. 

Por lo que se propondría a negocio como solución inicial estudiar la posibilidad de ofertar paquetes más básicos a un precio menor trando de captarles en el plazo de 1 año o 1 año y medio. De este modo se busca una fidelización que retornaría en ganancias más a medio largo plazo que al corto.

Todo ello teniendo en cuenta que el porcentaje a retener el de mas de un 26% de la clientela y que son muchos de ellos los que mensualmente una cuota más alta dejan en la compañia.

En cuanto al modelado para detectarlos, se ha llegado a un primer modelo final con una capacidad de detección del 76% de la cual aciertan quíen se va en un 71%. Es un buen comienzo que habría que seguir mejorando, investigando otras técnicas de feature engineering, probando con otros modelos e hiperparametros, quizás cambiando el modelo de predición de 0 o 1 a una probabilidad de ser 1 y por supuesto entrenando los algoritmos con nuevos datos.





