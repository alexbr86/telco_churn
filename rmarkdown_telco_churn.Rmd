---
title: "telco_churn"
author: "Alex Balseiro"
date: "18/6/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Inicialización
#### Funciones auxiliares para cargar paquetes y lista de paquetes

```{r}
prepare_packages <- function(packages){
  # Chequeamos que paquetes no estan instalados:
  non_intalled <- packages[!(packages %in% installed.packages()[, "Package"])]
  # En caso de existir alguno aún no instalado, lo instalamos:
  if (length(non_intalled)) 
    install.packages(non_intalled, dependencies = TRUE)
  # Cargamos toda la lista de paquetes:
  sapply(packages, require, character.only = TRUE)
}



packages <- c("tidyverse",
              "MASS",
              "car",
              "binr",
              "e1071",
              "caret",
              "cowplot",
              "caTools",
              "pROC",
              "ggcorrplot",
              "data.table",
              "Information",
              "rpart",
              "rpart.plot",
              "xgboost",
              "ROCR",
              "pROC",
              "GGally",
              "fastDummies"
)

prepare_packages(packages)
```


#### Cargar el dataset

```{r}
dataset <- read.csv("C:/Users/Alex/Desktop/Master&Bootcamp/Master/Modulo5/Trabajo individual/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv")

```

Se va a analizar el tipo de información que contiene el dataset

```{r}
glimpse(dataset)
```


Se va a cambiar los valores de la variable Senior Citizens valores categoricos de 'Yes', 'No'. Homogeneizando con el resto de variables categoricas.

```{r}
dataset$SeniorCitizen <- as.factor(ifelse(dataset$SeniorCitizen==1, 'Yes', 'No'))
```

```{r}
summary(dataset)
```

Tras ver el resumen, puede observarse que la variable TotalCharges tiene 11 NAs que habría que limipiar.Antes de ver que solución se le imputa al problema, es conveniente analizar el porqué son NAs, si es un fallo o hay algún motivo en los datos.

```{r}
dataset[is.na(dataset$TotalCharges),]
```

Tras analizar los 11 casos de NAs se ha observado que esto es debido a que son clientes recientes y no llevan aún ni un cargo acumulado, ya que como se ve en la columna Tenure llevan 0 meses en la compañia. Por lo que la mejor solución a este problema sería imputarles a todos un valor de 0. Primero se va a comprobar si hay más clientes que lleven 0 meses en la compañia y si tengan valor en TotalCharges

```{r}
dataset[dataset$tenure==0,]
```

Se comprueba que todos aquellos que llevan 0 meses son solo aquellos que tienen valores NA en TotalCharges. Por lo que se les va a asignar o como valor de pago acumulado en total.

```{r}
#Asignar valor 0 a todos aquellos que sean NA en TotalCharges
dataset[dataset$tenure==0, "TotalCharges"]=0
var_class <- sapply(dataset, class)
var_class_numeric <- names(dataset[var_class=="numeric"])
var_class_inter <- names(dataset[var_class=="integer"])
var_num_total <- c(var_class_numeric, var_class_inter)
var_numeric <- dataset[var_num_total]



```


## AutoML
Utilizando la libreria de H2O se va a probar como se comporta el dataset en limpio con un modelo y asi poder intuir de que modo proceder con el mismo.

Se va a dividir el dataset en train, validation y test.

```{r}
set.seed(46)
selected <- sample(1:nrow(dataset), 0.2*nrow(dataset))
train <- dataset[-selected,]
test <- dataset[selected,]

#Model
# Set names for h2o
target <- "Churn"
x <- setdiff(names(train), target)
```

Se va a lanzar todos los modelos supervisados excepto los referentes a Deep Learning y GLM.

```{r}
library(h2o)
h2o.init()
write.csv(train, file = "train.csv")
train2 = h2o.importFile("./train.csv")
write.csv(test, file = "test.csv")
test2 = h2o.importFile("./test.csv")
aml <- h2o.automl(x = x,
                 y = target,
                 validation_frame = test2,
                 training_frame = train2,
                 max_runtime_secs = 60,
                 exclude_algos = c("DeepLearning", "GLM", "DRF", "StackedEnsemble"))
```

Extraer los mejores modelos del train.
```{r}
automl_leader <- aml@leader
automl_leader_list <- aml@leaderboard
automl_leader_list

```

Ver la matriz de confusión

```{r}
h2o.confusionMatrix(automl_leader)
```

Variables más determinantes

```{r}
h2o.varimp_plot(automl_leader)
```


Las variables más determinantes teniendo en cuenta el mejor algoritmo seleccionado por AutoML son:
Contract: como variable más determinantes sería la duración del contrato.
TechSupport: la segunda más determinante si el cliente tiene soporte técnico.
Tenure: Es la tercera más determinante, cuanto tiempo lleva siendo cliente de la compañia.

## EDA

Ahora se va a analizar el dataset y sus variables. Con ello tratar de describir el dataset y obtener la mayor cantidad de información relevante para luego poder montar el modelo de predicción de abandono.

Primero se va a ver que porcentaje del dataset da positivo en abandono:
```{r}
options(repr.plot.width = 6, repr.plot.height = 4)
dataset %>% 
group_by(Churn) %>% 
summarise(Count = n())%>% 
mutate(percent = prop.table(Count)*100)%>%
ggplot(aes(reorder(Churn, -percent), percent), fill = Churn)+
geom_col(fill = c("#FF0800", "#170CEA"))+
geom_text(aes(label = sprintf("%.2f%%", percent)), hjust = 0.01,vjust = -0.5, size =3)+ 
theme_bw()+  
xlab("Churn") + 
ylab("Percent")+
ggtitle("Churn Percent")
```

Se puede observar que del dataset algo más de un 25% da positivo en abandono. Es una muestra bastante bien balanceada para lo que suele ser este tipo de casos, por lo que inicialmente podria ser viable descartar hacer down o up sampling.

Ahora vamos a ver como se distribuye la variable de Churn en el resto de variables categoricas:

```{r}
options(repr.plot.width = 12, repr.plot.height = 100)
plot_grid(ggplot(dataset, aes(x=gender,fill=Churn)) + geom_bar() + scale_fill_manual(values=c("#FF0800", "#170CEA")), 
          ggplot(dataset, aes(x=SeniorCitizen,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=Partner,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=Dependents,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=PhoneService,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=MultipleLines,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
            
            ggplot(dataset, aes(x=InternetService,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=OnlineSecurity,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=OnlineBackup,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=DeviceProtection,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=TechSupport,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
            
            ggplot(dataset, aes(x=StreamingTV,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=Contract,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=PaperlessBilling,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA")),
          ggplot(dataset, aes(x=PaymentMethod,fill=Churn))+ geom_bar(position = 'fill') + scale_fill_manual(values=c("#FF0800", "#170CEA"))
            
            + theme_bw()+
          scale_x_discrete(labels = function(x) str_wrap(x, width = 10)),
          align = 'v', ncol=2)

```


Se va a tratar de analizar del mismo modo, el comportamiento de las variables continuas con respecto la variable de abandono, Churn:

```{r}
dataset %>% ggplot(aes(x=TotalCharges,fill=Churn))+ geom_density(alpha=0.8)+scale_fill_manual(values=c("#FF0800", "#170CEA"))+labs(title='Total Charges desnisty split churn vs non churn' )
```


Como se puede comprobar con este gráfico podemos observar que los usuarios cuanto menos tienen acumulado de pago más tienden al abandono.


```{r}
dataset %>% ggplot(aes(x=MonthlyCharges,fill=Churn))+ geom_density(alpha=0.8)+scale_fill_manual(values=c("#FF0800", "#170CEA"))+labs(title='Monthly Charges desnisty split churn vs non churn' )
```

En cambio en el siguiente gráfico se puede observar que los que menos pagan mensualmente tienen a permanecer en la compañia mientras que los que más pagan tienen al abandono.


```{r}
dataset %>% ggplot(aes(x=tenure,fill=Churn))+ geom_density(alpha=0.8)+scale_fill_manual(values=c("#FF0800", "#170CEA"))+labs(title='Tenure desnisty split churn vs non churn' )
```

Con el gráfico que puede observarse arriba se ve la relación entre el tiempo que lleva el usuario en la compañia y el abandono. Donde hay una tendencia clara a cuanto menos tiempo lleven en la compañia más abandono hay. Mientras que a medida que van avanzando en el tiempo de estancia en la compañia la tendencia del abandono tiende a menos.


```{r}

ggpairs(var_numeric, title = "Distribución de las variables continuas")
```



Tras observar posibles correlaciones entre las variables continuas, se ve necesario ver la matriz de correlaciones para poder definir las posibles dependencias que se empiezan a observar en el gráfico de distribución de las variables continuas.

```{r}
corr <- cor(var_numeric,  method = "pearson", use = "complete.obs")
ggcorrplot(corr, hc.order = TRUE, type = "lower",
   lab = TRUE)
```


Tras analizar la matriz de correlaciones, puede observarse una alta dependencia positiva de la variable TotalCharges con Tenure y una algo más moderada con la otra variable MonthlyCharges.



#### Information value:


```{r}
dataset$Churn <- as.numeric(ifelse(dataset$Churn=='Yes', 1, 0))
iv_ds <- create_infotables(data=dataset,
                           y="Churn")

iv_summary <- iv_ds$Summary
iv_summary <- iv_summary[order(iv_summary$IV), ]
iv_summary$Variable <- factor(iv_summary$Variable, levels=iv_summary$Variable)

ggplot(iv_summary, aes(x=Variable, y=IV, fill = IV))+
  coord_flip() +
  scale_fill_gradient(low = "grey", high = "green") +
  geom_bar(stat = "identity")

```
  

WOE segun la  Contract:

```{r}
ggplot(iv_ds$Tables$Contract, aes(x=Contract, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```

```{r}
ggplot(iv_ds$Tables$tenure, aes(x=tenure, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```

```{r}
ggplot(iv_ds$Tables$OnlineSecurity, aes(x=OnlineSecurity, y=WOE, fill = WOE))+
  scale_fill_gradient(low = "red", high = "green") +
  geom_bar(stat = "identity")
```


## Modelado de los algoritmos

#### Preprocesamiento

Primeramente va a pasarse a variables dummies las categoricas para poder trabajar con ellas en los modelos.

```{r}

data_model <- dataset[,!names(dataset) %in% c("customerID")]
var_categoric <- names(data_model[,!names(data_model) %in% c(var_num_total, "Churn")])
data_model_dummy <- dummy_cols(data_model, select_columns = var_categoric, remove_first_dummy = TRUE)
data_model_dummy_only <- data_model_dummy[,!names(data_model_dummy) %in% var_categoric]                 


```

#### Dividir entre entrenamiento y test

```{r}
train <- createDataPartition(data_model_dummy_only$Churn, p = 0.75, list = F)
data_train <- data_model_dummy_only[train,]
data_test <- data_model_dummy_only[-train,]
dim(data_train)
dim(data_test)
```



#### Adaboost

```{r}
set.seed(825)
# Define train control for k fold cross validation
train_control <- trainControl(method="cv", number=10)
# Fit model
model <- train(Churn~., data=data_train, trControl=train_control, method="adaboost")
# Summarise Results
print(model)
```

#### Random Forest



